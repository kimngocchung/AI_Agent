# File: core/router.py (CONTEXT-AWARE ROUTER + QUERY EXPANSION)

import os
import re
from dotenv import load_dotenv
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableBranch, RunnableLambda, RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.documents import Document

# Import c√°c chain con v√† retriever
from .chains.full_plan_chain import full_plan_chain    # LU·ªíNG 2 (L√™n k·∫ø ho·∫°ch)
from .chains.prompts import router_prompt, rag_direct_prompt
from .chains.retriever import retrieve_docs_with_filter

# <<< IMPORT LU·ªíNG M·ªöI (LU·ªíNG 3) >>>
from .agents.executor import agent_executor           # LU·ªíNG 3 (Th·ª±c thi)

load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError("GEMINI_API_KEY kh√¥ng ƒë∆∞·ª£c t√¨m th·∫•y")

# LLM cho router ph√¢n lo·∫°i (Flash)
router_llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash",
                                  google_api_key=api_key)

# LLM cho vi·ªác t·∫°o c√¢u tr·∫£ l·ªùi cu·ªëi c√πng
answer_llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash",
                                  google_api_key=api_key,
                                  temperature=0.3)

# H√†m helper ƒë·ªÉ ƒë·ªãnh d·∫°ng context t·ª´ retriever
def format_docs(docs: list[Document]) -> str:
    if not isinstance(docs, list) or not docs:
        print("üî¥ [RAG DEBUG] Kh√¥ng t√¨m th·∫•y documents n√†o!")
        return "Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong c∆° s·ªü tri th·ª©c."
    
    top_k_docs = docs[:5]
    
    print(f"\n{'='*60}")
    print(f"üü¢ [RAG DEBUG] T√¨m th·∫•y {len(docs)} documents, l·∫•y top {len(top_k_docs)}")
    for i, doc in enumerate(top_k_docs):
        source = doc.metadata.get('source', 'N/A')
        content_preview = doc.page_content[:200].replace('\n', ' ')
        print(f"  üìÑ Doc {i+1}: {source}")
        print(f"     Preview: {content_preview}...")
    print(f"{'='*60}\n")
    
    return "\n\n---\n\n".join(
        f"Ngu·ªìn: {doc.metadata.get('source', 'N/A')}\n\n{doc.page_content}"
        for doc in top_k_docs
    )

# H√†m helper ƒë·ªÉ format chat history
def format_chat_history(chat_history: list) -> str:
    if not chat_history:
        return "(Kh√¥ng c√≥ l·ªãch s·ª≠ h·ªôi tho·∫°i)"
    
    # L·∫•y 6 tin nh·∫Øn g·∫ßn nh·∫•t (3 c·∫∑p user-assistant)
    recent_messages = chat_history[-6:]
    
    formatted = []
    for msg in recent_messages:
        role = msg.get("role", "unknown")
        content = msg.get("content", "")[:300]
        if role == "user":
            formatted.append(f"üë§ User: {content}")
        elif role == "assistant":
            formatted.append(f"ü§ñ Assistant: {content}")
    
    return "\n".join(formatted) if formatted else "(Kh√¥ng c√≥ l·ªãch s·ª≠ h·ªôi tho·∫°i)"

# H√†m tr√≠ch xu·∫•t keywords t·ª´ chat history ƒë·ªÉ m·ªü r·ªông query
def extract_context_keywords(chat_history: list) -> str:
    """
    Tr√≠ch xu·∫•t keywords quan tr·ªçng t·ª´ chat history g·∫ßn ƒë√¢y.
    Ch·ªâ th√™m context khi th·ª±c s·ª± c·∫ßn thi·∫øt (v√≠ d·ª•: CVE codes, t√™n tool, target IP...)
    """
    if not chat_history:
        return ""
    
    keywords = []
    
    # Pattern ƒë·ªÉ t√¨m CVE codes
    cve_pattern = re.compile(r'CVE-\d{4}-\d{4,}', re.IGNORECASE)
    # Pattern ƒë·ªÉ t√¨m IP addresses
    ip_pattern = re.compile(r'\b(?:\d{1,3}\.){3}\d{1,3}\b')
    # Pattern ƒë·ªÉ t√¨m tool names ph·ªï bi·∫øn
    tool_pattern = re.compile(r'\b(nmap|metasploit|burp|nikto|sqlmap|hydra|john|hashcat|gobuster|dirb|ffuf)\b', re.IGNORECASE)
    
    # Ch·ªâ xem 4 tin nh·∫Øn g·∫ßn nh·∫•t
    recent_messages = chat_history[-4:]
    
    for msg in recent_messages:
        content = msg.get("content", "")
        
        # T√¨m CVE codes
        cves = cve_pattern.findall(content)
        keywords.extend(cves)
        
        # T√¨m IP addresses (ch·ªâ khi c√≥ CVE li√™n quan)
        if cves:
            ips = ip_pattern.findall(content)
            keywords.extend(ips[:1])  # Ch·ªâ l·∫•y 1 IP ƒë·∫ßu ti√™n
        
        # T√¨m tool names
        tools = tool_pattern.findall(content)
        keywords.extend(tools)
    
    # Lo·∫°i b·ªè duplicate v√† gi·ªõi h·∫°n s·ªë l∆∞·ª£ng
    unique_keywords = list(dict.fromkeys(keywords))[:5]
    
    return " ".join(unique_keywords)

# H√†m chu·∫©n b·ªã input cho c√°c subchain
def prepare_subchain_input(x: dict) -> dict:
    """
    Chu·∫©n b·ªã input dict cho c√°c subchain (agent_executor, full_plan_chain).
    """
    return {
        "user_input": x.get("user_input", ""),
        "chat_history": format_chat_history(x.get("chat_history", [])),
        "rag_context": format_docs(x.get("rag_context_docs", [])),
        "selected_sources": x.get("selected_sources", None)
    }

# H√†m debug ƒë·ªÉ log th√¥ng tin ph√¢n lo·∫°i
def log_classification(input_dict: dict) -> dict:
    topic = input_dict.get("topic", "UNKNOWN")
    user_input = input_dict.get("user_input", "")[:50]
    rag_docs = input_dict.get("rag_context_docs", [])
    selected_sources = input_dict.get("selected_sources", [])
    
    print(f"\n{'='*60}")
    print(f"üîµ [ROUTER DEBUG] Topic: {topic}")
    print(f"   User Input: {user_input}...")
    print(f"   RAG Docs Count: {len(rag_docs) if rag_docs else 0}")
    print(f"   Selected Sources: {len(selected_sources) if selected_sources else 'All'}")
    print(f"{'='*60}\n")
    
    return input_dict

# Chain RAG Tr·ª±c ti·∫øp (LU·ªíNG 1)
direct_rag_answer_chain = (
    rag_direct_prompt
    | answer_llm
    | StrOutputParser()
)

def create_router():
    """
    T·∫°o Router Chain th√¥ng minh: 
    Ph√¢n lo·∫°i -> Ki·ªÉm tra RAG -> Ch·ªçn 1 trong 3 Lu·ªìng.
    """
    
    # 1. Chain ph√¢n lo·∫°i √Ω ƒë·ªãnh - TRUY·ªÄN CHAT HISTORY ƒê·ªÇ HI·ªÇU CONTEXT
    def classify_with_history(x):
        return {
            "user_input": x["user_input"],
            "chat_history": format_chat_history(x.get("chat_history", []))
        }
    
    classifier_chain = RunnableLambda(classify_with_history) | router_prompt | router_llm | StrOutputParser()

    # 2. Chain L·∫•y Context RAG S·ªõm - M·ªû R·ªòNG QUERY D·ª∞A TR√äN CHAT HISTORY
    def early_rag_with_filter(x):
        user_input = x["user_input"]
        chat_history = x.get("chat_history", [])
        
        # Tr√≠ch xu·∫•t keywords t·ª´ chat history ƒë·ªÉ m·ªü r·ªông query
        context_keywords = extract_context_keywords(chat_history)
        
        # N·∫øu c√≥ context keywords, th√™m v√†o query
        if context_keywords:
            expanded_query = f"{user_input} {context_keywords}"
            print(f"üîç [QUERY EXPANSION] Original: '{user_input}' ‚Üí Expanded: '{expanded_query}'")
        else:
            expanded_query = user_input
        
        return retrieve_docs_with_filter({
            "user_input": expanded_query,
            "selected_sources": x.get("selected_sources", None)
        })
    
    early_rag_retrieval_chain = RunnableLambda(early_rag_with_filter)

    # 3. Logic Ph√¢n nh√°nh 3 Lu·ªìng
    branch = RunnableBranch(
        
        # ƒêI·ªÄU KI·ªÜN 1: TH·ª∞C THI (LU·ªíNG 3)
        (lambda x: "execute_pentest_tool" in x["topic"],
            RunnableLambda(prepare_subchain_input) | agent_executor
        ),
        
        # ƒêI·ªÄU KI·ªÜN 2: VULNERABILITY ho·∫∑c TOOL (LU·ªíNG 1)
        (lambda x: "specific_vulnerability_info" in x["topic"] or "tool_usage" in x["topic"],
            RunnableLambda(
                lambda x: {
                    "user_input": x["user_input"],
                    "rag_context": format_docs(x.get("rag_context_docs", [])),
                    "chat_history": format_chat_history(x.get("chat_history", []))
                }
            ) | direct_rag_answer_chain
        ),
        
        # FALLBACK: (LU·ªíNG 2 - L√™n k·∫ø ho·∫°ch)
        RunnableLambda(prepare_subchain_input) | full_plan_chain
    )

    # 4. G·∫Øn k·∫øt t·∫•t c·∫£ l·∫°i
    final_chain = RunnablePassthrough.assign(
        topic=classifier_chain,
        rag_context_docs=early_rag_retrieval_chain
    ) | RunnableLambda(log_classification) | branch

    return final_chain